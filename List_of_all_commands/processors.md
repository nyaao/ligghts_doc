# processors command

## 構文
```
processors Px Py Pz keyword args ...
```
Px, Py, Pz = シミュレーションドメインに重ねられた3次元グリッドの各次元のプロセッサ数
ゼロ個以上のキーワード/引数ペアを追加可能
キーワード = grid、map、part、file

grid 引数 = gstyle パラメータ...  
gstyle = onelevel または twolevel または numa または custom  
onelevel パラメータ = none  
twolevel パラメータ = Nc Cx Cy Cz  
Nc = ノードあたりのコア数  
Cx, Cy, Cz = 各ノードに割り当てられた3次元サブグリッドの各次元のコア数  
numa パラメータ = none  
custom パラメータ = infile  
infile = グリッドレイアウトを含むファイル  
map 引数 = cart または cart/reorder または xyz または xzy または yxz または yzx または zxy または zyx  
cart = MPI_Cart() メソッドを使用してプロセッサを3次元グリッドにマップし、reorder = 0 を使用  
cart/reorder = MPI_Cart() メソッドを使用してプロセッサを3次元グリッドにマップし、reorder = 1 を使用  
xyz, xzy, yxz, yzx, zxy, zyx = IJK順で3次元グリッドにプロセッサをマップ  
numa 引数 = none  
part 引数 = Psend, Precv, cstyle  
Psend = パーティション番号 # (1 ～ Np) 送信するプロセッサレイアウト  
Precv = パーティション番号 # (1 ～ Np) 受信するプロセッサレイアウト  
cstyle = multiple  
multiple = Psend グリッドは各次元で Precv グリッドの倍数  
file 引数 = outfile  
outfile = 3次元プロセッサグリッドを書き込むファイル名  

## 例
```
processors * * 5
processors 2 4 4
processors * * 8 map xyz
processors * * * grid numa
processors * * * grid twolevel 4 * * 1
processors 4 8 16 grid custom myfile
processors * * * part 1 2 multiple
```

## 説明
プロセッサがグローバルシミュレーションボックスに対して3次元論理グリッドとしてどのようにマッピングされるかを指定します。これは2つのステップで行われます。最初に、P個のプロセッサがある場合、P = Px × Py × Pz の因数分解を選択する必要があります。つまり、x軸方向にPx個、y軸方向にPy個、z軸方向にPz個のプロセッサを配置します。次に、P個のプロセッサが論理的な3次元グリッドにマッピングされます。このコマンドの引数は、これらの2つのステップのそれぞれを制御します。

Px, Py, Pzパラメータは因数分解に影響します。これらの3つのパラメータのいずれかにアスタリスク「*」を指定することができます。これは、LIGGGHTS(R)-PUBLICがその次元のプロセッサ数を自動的に選択することを意味します。LIGGGHTS(R)-PUBLICは、グローバルシミュレーションボックスのサイズと形状に基づいて、各プロセッサのサブドメインの表面積と体積の比率を最小限に抑えるように選択します。

LIGGGHTS(R)-PUBLICは、3Dプロセッサグリッドを動的に変更して負荷分散を行わないため、Px、Py、Pzに明示的な値を指定することで、特定の問題に対してLIGGGHTS(R)-PUBLICのデフォルト設定を上書きすることができます。例えば、シミュレーション中に特定の次元で原子の分布が劇的に変化するような問題では、最適でない場合があります。

Px、Py、Pzの積は、LIGGGHTS(R)-PUBLICが使用するプロセッサの総数Pと一致しなければなりません。[2Dシミュレーション]()の場合、Pzは1である必要があります。

また、Pが素数のプロセッサ数である場合、1 x P x 1のようなグリッドが必要になり、各プロセッサのサブドメインの表面積が大きいため、追加の通信コストが発生する可能性があることに注意してください。

また、複数のパーティションを使用している場合、Pはこのパーティション内のプロセッサ数を意味します。-partition コマンドラインスイッチの説明については、こちらのセクションを参照してください。また、processors コマンドに [partition]() コマンドを接頭辞として付けることで、異なるパーティションに対して異なる Px, Py, Pz の値を簡単に指定することができます。

例えば、次のように partition コマンドを使用して、異なるパーティションに異なるプロセッサグリッドを指定できます。
```
partition yes 1 processors 4 4 4
partition yes 2 processors 2 3 2
```

grid キーワードは、P を Px, Py, Pz に分解する際に影響を与えるだけでなく、P のプロセッサ ID が 3D プロセッサグリッドにどのようにマッピングされるかにも影響を与えます。

onelevel スタイルは、Px, Py, Pz 設定に適合する 3D グリッドを作成し、各プロセッサのサブドメインの表面積対体積比を最小化します（上記のように）。プロセッサのグリッドへのマッピングは、map キーワードの設定によって決まります。

twolevel スタイルは、マルチコアノードを備えた機械でオフノード通信を最小化するために使用できます。これにより、3D グリッドの連続するサブセクションが各ノードのすべてのコアに割り当てられることが保証されます。例えば、Nc が 4 の場合、3D グリッドの 2x2x1、2x1x2、または 1x2x2 のサブセクションが各ノードのコアに対応します。これは、分解とマッピングの両方のステップに影響を与えます。

Cx, Cy, Cz の設定は Px, Py, Pz の設定と似ており、ただしその積は Nc に等しくする必要があります。3つのパラメータのいずれかにアスタリスク "*" を指定することができ、これは LIGGGHTS(R)-PUBLIC がその次元におけるノードのサブグリッドのコア数を自動的に選択することを意味します。Px, Py, Pz と同様に、LIGGGHTS(R)-PUBLIC はグローバルシミュレーションボックスのサイズと形状に基づいて、各プロセッサのサブドメインの表面積対体積比を最小化するように選択を行います。

[!WARNING]twolevel スタイルが正しく機能するためには、LIGGGHTS(R)-PUBLIC が実行されているプロセッサの MPI ランクがコア単位で、次にノード単位で並べられていることを前提としています。例えば、2つのクアッドコアノードで合計8プロセッサを実行している場合、プロセッサ0,1,2,3はノード1に、プロセッサ4,5,6,7はノード2に配置されていると仮定します。これはほとんどのMPI実装のデフォルトのランク順序ですが、いくつかのMPIではこの順序を変更するオプションを提供しています（例えば、環境変数の設定を通じて）。

numa スタイルは、twolevel キーワードと似たように動作しますが、どのコアがどのノードで実行されているかを自動的に検出します。現在、この機能は2レベルでのみ行われていますが、将来的にはソケットトポロジーやその他の非均一メモリアクセス（NUMA）コストを考慮するように拡張される可能性があります。また、simulation box を3Dプロセッサグリッドに分割してノード間通信を最小化するための2レベルの因数分解を行う際に、twolevel キーワードとは異なるアルゴリズムを使用し、ノードとコアを論理的な3Dグリッドにマッピングするために独自のMPIベースのマッピングを行います。そのため、プロセッサのレイアウトは twolevel オプションとは異なるものになる場合があります。

numa スタイルは、MPIプロセスの数がノードごとに使用されるコアの数で割り切れない場合、または Px, Py, Pz の値のいずれかが1より大きい場合にエラーを発生させます。

[!WARNING]twolevel スタイルとは異なり、numa スタイルは正しく動作するために MPI ランクの特定の順序を必要としません。これは、どのプロセスがどのノードで実行されているかを自動的に検出するためです。

custom スタイルは、infile ファイルを使用して、3D 因数分解とプロセッサのグリッドへのマッピングの両方を定義します。

ファイルは次の形式である必要があります。最初に任意の数の空白行やコメント行（「#」文字で始まる行）が存在できます。最初の非空白で非コメント行には、次の3つの値が必要です：

```
Px Py Py
```

これらは、プロセッサーコマンドの Px、Py、Pz 設定と総プロセッサ数と互換性がある必要があります。

この行の直後に、次の形式で P = PxPyPz 行が続く必要があります：
```
ID I J K
```

ID はプロセッサ ID（0 から P-1 の範囲）で、I, J, K は 3D グリッド内でのプロセッサの位置を示します。I は 1 から Px の範囲でなければならず、J と K も同様です。P 行は任意の順序でリストできますが、同じプロセッサ ID が 2 回以上登場してはいけません。

map キーワードは、P のプロセッサ ID（0 から P-1）の 3D グリッドへのマッピング方法に影響します。これは、onelevel および twolevel グリッド設定でのみ使用されます。

cart スタイルは、MPI_Cart_create()、MPI_Cart_get()、MPI_Cart_shift()、MPI_Cart_rank() といった MPI のカートesian関数群を使用してマッピングを実行します。これにより、MPI_Cart_create() 関数が reorder フラグ = 0 で呼び出され、MPI がプロセッサの順序を自由に変更しないようにします。

cart/reorder スタイルは cart スタイルと同じことを行いますが、reorder フラグを 1 に設定するため、MPI がプロセッサを再順序付けすることができます。

xyz、xzy、yxz、yzx、zxy、zyx スタイルはすべて似ています。スタイルが IJK の場合、P プロセッサはグリッドにマッピングされ、I 軸方向のプロセッサ ID が最も速く変化し、次に J 軸方向のプロセッサ ID が変化し、K 軸方向のプロセッサ ID が最も遅く変化します。例えば、style xyz を選択し、2x2x2 の 8 プロセッサのグリッドがある場合、シミュレーション領域の 8 つのオクタントの割り当ては次のようになります：

```
proc 0 = lo x, lo y, lo z octant
proc 1 = hi x, lo y, lo z octant
proc 2 = lo x, hi y, lo z octant
proc 3 = hi x, hi y, lo z octant
proc 4 = lo x, lo y, hi z octant
proc 5 = hi x, lo y, hi z octant
proc 6 = lo x, hi y, hi z octant
proc 7 = hi x, hi y, hi z octant
```

基本的に、特定のマシン上の MPI 実装は、そのマシンのネットワークトポロジーと、シミュレーションに割り当てられたプロセッサおよびノードの特定のサブセットを認識しているべきです。したがって、MPI_Cart 呼び出しは、MPI プロセスの 3D グリッドへの割り当てを最適化して通信コストを最小化できるはずです。しかし、実際には、ほとんどの MPI 実装はこれを実行しないため、cart および cart/reorder スタイルは、IJK スタイルのいずれかと同じ結果を出す可能性が高いです。

また、twolevel グリッドスタイルでは、map 設定が最初にノードを 3D グリッドにマッピングし、その後各ノード内のコアに再度マッピングします。後者のステップでは、cart および cart/reorder スタイルはサポートされていないため、その代わりに xyz スタイルが使用されます。

part キーワードは、P を Px, Py, Pz に分解する際の因子分解に影響を与えます。

これは、マルチパーティションモードで実行する際に役立ちます。例えば、[run_style verlet/split]() コマンドを使用する場合です。このキーワードは、プロセッサをシミュレーションボックスにマッピングする際に、送信パーティション Psend と受信パーティション Precv の間に依存関係を指定します。この依存関係は、各パーティションが自分自身のプロセッサのマッピングを設定する際に強制されます。Psend と Precv はそれぞれ 1 から Np の整数でなければならず、Np は [-partition command-line switch]()で定義したパーティションの数です。

「依存関係」とは、送信パーティションが自分の 3D 論理グリッドを Px, Py, Pz の形式で作成し、それが完了した後に、送信パーティションが Px, Py, Pz の値を受信パーティションに送信することを意味します。受信パーティションは、これらの値を受信してから自分自身の 3D 論理グリッドを作成し、送信パーティションの Px, Py, Pz の値を制約として使用します。制約の性質は、cstyle 引数によって決まります。

cstyle が multiple の場合、送信パーティションのプロセッサグリッドの各次元は、受信パーティションのプロセッサグリッドの対応する次元の整数倍である必要があります。これは、[run_style verlet/split]() コマンドの要件です。

例えば、送信パーティションが 4x6x10 のグリッド（240 プロセッサ）を作成する場合、受信パーティションが 80 プロセッサで実行されると、4x2x10 のグリッドを作成することはできますが、2x4x10 のグリッドは作成できません。なぜなら、y 次元で 6 が 4 の整数倍ではないからです。

[!WARNING][partition]() コマンドを使用して、異なるパーティションに異なる「processors」コマンドを呼び出し、さらに part キーワードも使用する場合、送信パーティションと受信パーティションの両方が、part キーワードを使用して 2 つのパーティションを接続する「processors」コマンドを呼び出すことを確認する必要があります。LIGGGHTS(R)-PUBLIC はこれを簡単にチェックできませんが、このエラーが発生すると、シミュレーションはセットアップ段階で停止する可能性があります。

file キーワードは、P プロセッサの因数分解と、それらが 3D グリッドにマッピングされる様子を指定されたファイル outfile に書き込みます。これは、物理プロセッサが希望通りに割り当てられたかを確認するのに役立ちます。特に複数のパーティションで実行している場合や、マルチコアマシンで実行している場合、あるいは [-reorder command-line switch]()を使用してプロセッサのランクが再順序付けされた場合や、MPI 固有の起動オプション（設定ファイルの使用など）を使用した場合など、割り当てが難しいことがあります。

複数のパーティションがある場合、各パーティションが異なるファイルに書き込むように確認する必要があります。たとえば、ファイル名に[word-style variable]()を使用することができます。ファイルにはわかりやすいヘッダーがあり、その後に各プロセッサについて1行が次の形式で続きます：

ID はそれぞれ、このシミュレーション（ワールド）、複数のシミュレーションを含むユニバース、および LIGGGHTS(R)-PUBLIC を初期化するために使用した元の MPI コミュニケーターでのプロセッサのランクを示します。ワールド ID とユニバース ID は、複数のパーティションで実行している場合にのみ異なります。詳細は [-partition command-line switch]()を参照してください。ユニバース ID と元の ID は、[-reorder command-line switch]()を使用してプロセッサの順序を元のコミュニケーターでのランクとは異なる順序に変更した場合にのみ異なります。

I, J, K は 3D 論理グリッド内のプロセッサのインデックスで、各インデックスは 1 から Nd の範囲で、Nd はその次元のグリッド内のプロセッサの数です。

name は MPI_Get_processor_name() の呼び出しで返される名前で、物理的なプロセッサに関連する識別子を表すべきです。MPI 実装によっては、複数のコアが同じ名前を持つ場合があることに注意してください。

## 制限事項
このコマンドは、[read_data]() や [create_box]() コマンドでシミュレーションボックスが定義された後には使用できません。再起動ファイルを読み込む前に使用することで、再起動ファイルで指定されたものから 3D プロセッサグリッドを変更できます。

grid numa キーワードは現在、map cart オプションでのみ動作します。

part キーワード（受信パーティション用）は、grid onelevel または grid twolevel オプションでのみ動作します。

## 関連コマンド
[partition](), [-reorder command-line switch]()

## デフォルト
オプションのデフォルト値は、Px Py Pz = * * *、grid = onelevel、および map = cart です。
